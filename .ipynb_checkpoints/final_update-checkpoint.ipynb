{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac49da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# import mpldatacursor\n",
    "\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfReader\n",
    "from matplotlib.widgets import Cursor, SpanSelector\n",
    "\n",
    "# import pytesseract\n",
    "import easyocr\n",
    "import keras_ocr\n",
    "from keras_ocr.tools import drawAnnotations\n",
    "import re\n",
    "import os\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', None)   # Show all rows\n",
    "pd.set_option('display.max_columns', None)   # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to multiple lines\n",
    "\n",
    "# # Reset display options to default values or your preferred values\n",
    "# pd.reset_option('display.max_rows')\n",
    "# pd.reset_option('display.max_columns')\n",
    "# pd.reset_option('display.expand_frame_repr')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0b1c2",
   "metadata": {},
   "source": [
    "### Extracting Images from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd2bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_images_from_pdf(pdf_path, output_folder):\n",
    "#     # Create the output folder if it doesn't exist\n",
    "#     os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#     # Load the PDF file\n",
    "#     pdf_reader = PdfReader(pdf_path)\n",
    "\n",
    "#     # Loop through each page of the PDF\n",
    "#     for page_number, page in enumerate(pdf_reader.pages):\n",
    "#         # Extract images from the page\n",
    "#         xObject = page['/Resources']['/XObject'].get_object()\n",
    "#         image_counter = 0\n",
    "\n",
    "#         for obj in xObject:\n",
    "#             if xObject[obj]['/Subtype'] == '/Image':\n",
    "#                 size = (xObject[obj]['/Width'], xObject[obj]['/Height'])\n",
    "#                 data = xObject[obj].get_object()\n",
    "\n",
    "#                 if '/Filter' in data:\n",
    "#                     if data['/Filter'] == '/FlateDecode':\n",
    "#                         img = Image.frombytes('RGB', size, data.get_data())\n",
    "#                         img.save(os.path.join(output_folder, f\"page_{page_number + 1}_image_{image_counter}.png\"))\n",
    "#                         image_counter += 1\n",
    "#                     elif data['/Filter'] == '/DCTDecode':\n",
    "#                         img = open(os.path.join(output_folder, f\"page_{page_number + 1}_image_{image_counter}.jpg\"), \"wb\")\n",
    "#                         img.write(data.get_data())\n",
    "#                         img.close()\n",
    "#                         image_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154ba18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_path=os.getcwd()\n",
    "# pdf_file_path = os.path.join(current_path,\"data\",\"Jewelosco.pdf\")\n",
    "# output_image_folder_path = os.path.join(current_path,\"output\")\n",
    "\n",
    "# extract_images_from_pdf(pdf_file_path, output_image_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3930aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbdb0800",
   "metadata": {},
   "source": [
    "### EasyOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baccba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob('C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0193e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "reader = easyocr.Reader(['en'])\n",
    "# reader = easyocr.Reader(['en'], gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaaf7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee14f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_10_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_11_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_12_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_13_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_1_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_2_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_3_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_4_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_5_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_6_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_7_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_8_image_0.jpg\n",
      "C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\page_9_image_0.jpg\n"
     ]
    }
   ],
   "source": [
    "for image_name in image_files:\n",
    "    print(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d777d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ef82755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output\\\\page_10_image_0.jpg'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5817f85c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m image_no\u001b[38;5;241m=\u001b[39mi\n\u001b[0;32m      4\u001b[0m img_name_temp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(image_files[i]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimage_no\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Create the DataFrame\u001b[39;00m\n\u001b[0;32m      9\u001b[0m bbox_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconf\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\easyocr\\easyocr.py:464\u001b[0m, in \u001b[0;36mReader.readtext\u001b[1;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[0;32m    463\u001b[0m horizontal_list, free_list \u001b[38;5;241m=\u001b[39m horizontal_list[\u001b[38;5;241m0\u001b[39m], free_list[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 464\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_cv_grey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizontal_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfree_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeamWidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocklist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotation_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mparagraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrast_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjust_contrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfilter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\easyocr\\easyocr.py:384\u001b[0m, in \u001b[0;36mReader.recognize\u001b[1;34m(self, img_cv_grey, horizontal_list, free_list, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, contrast_ths, adjust_contrast, filter_ths, y_ths, x_ths, reformat, output_format)\u001b[0m\n\u001b[0;32m    382\u001b[0m     f_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    383\u001b[0m     image_list, max_width \u001b[38;5;241m=\u001b[39m get_image_list(h_list, f_list, img_cv_grey, model_height \u001b[38;5;241m=\u001b[39m imgH)\n\u001b[1;32m--> 384\u001b[0m     result0 \u001b[38;5;241m=\u001b[39m \u001b[43mget_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharacter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mignore_char\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeamWidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrast_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjust_contrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m result0\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bbox \u001b[38;5;129;01min\u001b[39;00m free_list:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\easyocr\\recognition.py:218\u001b[0m, in \u001b[0;36mget_text\u001b[1;34m(character, imgH, imgW, recognizer, converter, image_list, ignore_char, decoder, beamWidth, batch_size, contrast_ths, adjust_contrast, filter_ths, workers, device)\u001b[0m\n\u001b[0;32m    214\u001b[0m     test_data \u001b[38;5;241m=\u001b[39m ListDataset(img_list2)\n\u001b[0;32m    215\u001b[0m     test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m    216\u001b[0m                     test_data, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    217\u001b[0m                     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(workers), collate_fn\u001b[38;5;241m=\u001b[39mAlignCollate_contrast, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 218\u001b[0m     result2 \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconverter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_max_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mignore_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_group_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeamWidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, zipped \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(coord, result1)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\easyocr\\recognition.py:111\u001b[0m, in \u001b[0;36mrecognizer_predict\u001b[1;34m(model, converter, test_loader, batch_max_length, ignore_idx, char_group_idx, decoder, beamWidth, device)\u001b[0m\n\u001b[0;32m    108\u001b[0m length_for_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mIntTensor([batch_max_length] \u001b[38;5;241m*\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    109\u001b[0m text_for_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(batch_size, batch_max_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfill_(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m--> 111\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_for_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Select max probabilty (greedy decoding) then decode index to character\u001b[39;00m\n\u001b[0;32m    114\u001b[0m preds_size \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mIntTensor([preds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m*\u001b[39m batch_size)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\easyocr\\model\\vgg_model.py:25\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, input, text)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, text):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124;03m\"\"\" Feature extraction stage \"\"\"\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     visual_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFeatureExtraction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     visual_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool(visual_feature\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     27\u001b[0m     visual_feature \u001b[38;5;241m=\u001b[39m visual_feature\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\easyocr\\model\\modules.py:124\u001b[0m, in \u001b[0;36mVGG_FeatureExtractor.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConvNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_df= pd.DataFrame( columns=['bbox', 'text', 'conf'])\n",
    "for i in range(len (image_files)):\n",
    "    image_no=i\n",
    "    img_name_temp=str(image_files[i].split('\\\\')[-1]).split('.')[0]\n",
    "    results = reader.readtext(image_files[image_no])\n",
    "\n",
    "\n",
    "    # Create the DataFrame\n",
    "    bbox_df = pd.DataFrame(results, columns=['bbox', 'text', 'conf'])\n",
    "\n",
    "    # Convert the 'text' column to lowercase and filter rows where the lowercase text starts with the strings\n",
    "    filtered_df = bbox_df[bbox_df['text'].str.lower().str.startswith(('digh', 'reb', 'digital', 'coup', 'dig'), na=False)]\n",
    "\n",
    "    strings_list = ['digital rebate', 'digital coupon']\n",
    "\n",
    "    # Find the maximum length among the given strings\n",
    "    max_length = max(len(s) for s in strings_list)\n",
    "\n",
    "    # Filter the DataFrame based on the maximum length\n",
    "    filtered_df = filtered_df[filtered_df['text'].str.len() <= max_length]\n",
    "\n",
    "    import re\n",
    "\n",
    "    img_id = image_files[image_no].split('\\\\')[-1]\n",
    "    print(img_id)\n",
    "    # Use regular expression to extract the number after \"page_\"\n",
    "    page_number = re.search(r'page_(\\d+)', img_id).group(1)\n",
    "    filtered_df['page_number'] = page_number\n",
    "\n",
    "\n",
    "    #### Checking if the strings are close to one another , if yes then merge it\n",
    "    # **Calculated the central distance**\n",
    "\n",
    "    def horizontal_distance(bbox1, bbox2):\n",
    "        x1, y1 = bbox1[0]\n",
    "        x2, y2 = bbox1[1]\n",
    "        x3, y3 = bbox2[0]\n",
    "        x4, y4 = bbox2[1]\n",
    "\n",
    "        center1_x = (x1 + x2) / 2\n",
    "        center2_x = (x3 + x4) / 2\n",
    "        return abs(center1_x - center2_x)\n",
    "\n",
    "        # Function to check if the second word is not 'coupon' or 'rebate'\n",
    "    def check_second_word(text):\n",
    "        words = text.lower().split()\n",
    "        if len(words)==2:\n",
    "            return words[1] in ['coupon', 'rebate']\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def check_length(text):\n",
    "        w_text = text.lower().split()\n",
    "        words = max(len('coupon'), len('rebate'), len('digital'))\n",
    "        # print('Threshold length:',words)\n",
    "        if len(w_text) == 1:\n",
    "            # print('Actual Word Length:', len(w_text[0]))\n",
    "            return len(w_text[0])<=words\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    \n",
    "    if not filtered_df.empty:\n",
    "        # Filtering out records with \"coupon\" or \"rebate\" in the second string\n",
    "        filtered_df = filtered_df[filtered_df['text'].apply(check_second_word)]\n",
    "        # Apply the function on 'text_column' and create a boolean mask\n",
    "        filtered_df = filtered_df[filtered_df['text'].apply(check_length)]\n",
    "\n",
    "        \n",
    "    # Group bounding boxes that are close horizontally and aggregate the 'text' column as a single string\n",
    "    grouped_text = []\n",
    "    grouped_conf = []\n",
    "    grouped_indices = []  # To keep track of already grouped indices\n",
    "    group_threshold = 20  # Adjust this threshold as needed based on the data\n",
    "\n",
    "    for idx, row in filtered_df.iterrows():\n",
    "        if idx in grouped_indices:\n",
    "            continue  # Skip if the current row is already grouped\n",
    "\n",
    "        text = row['text']\n",
    "        conf = row['conf']\n",
    "        grouped = False\n",
    "\n",
    "        # Group rows that are close horizontally\n",
    "        group_rows = [idx]  # List to hold the indices of the grouped rows\n",
    "        for _, row2 in filtered_df.iterrows():\n",
    "            if _ == idx or _ in grouped_indices:\n",
    "                continue  # Skip if the current row is itself or already grouped\n",
    "            if horizontal_distance(row['bbox'], row2['bbox']) <= group_threshold:\n",
    "                print(_, idx)\n",
    "                text += ' ' + row2['text']\n",
    "                filtered_df.at[idx, 'text'] = text\n",
    "                filtered_df = filtered_df.drop(_)\n",
    "\n",
    "                conf = max(conf, row2['conf'])\n",
    "                filtered_df.at[idx, 'conf'] = conf\n",
    "                grouped_indices.append(_)\n",
    "                group_rows.append(_)\n",
    "                grouped = True\n",
    "\n",
    "        if grouped:\n",
    "            grouped_text.append(text)\n",
    "            grouped_conf.append(conf)\n",
    "            grouped_indices.append(idx)\n",
    "            print(grouped_text)\n",
    "            print(grouped_conf)\n",
    "\n",
    "    grouped_data = {'text': grouped_text, 'conf': grouped_conf}\n",
    "    grouped_df = pd.DataFrame(grouped_data)\n",
    "\n",
    "    print(filtered_df.columns)\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    replace_mapping = {\n",
    "        'COUPON': 'DIGITAL COUPON',\n",
    "        'REBATE': 'DIGITAL REBATE',\n",
    "        'DIghAl COUPON': 'DIGITAL COUPON',\n",
    "        'DIGgal COUPON': 'DIGITAL COUPON',\n",
    "\n",
    "    }\n",
    "    \n",
    "    if not filtered_df.empty:\n",
    "        filtered_df['text'] = filtered_df['text'].replace(replace_mapping)\n",
    "\n",
    "\n",
    "    #////////////////////////////////img   \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    easy_results = filtered_df[['text','bbox']].values.tolist()\n",
    "    # print(easy_results)\n",
    "\n",
    "    easy_results = [(x[0], np.array(x[1])) for x in easy_results]\n",
    "    # print(easy_results)\n",
    "\n",
    "    keras_ocr.tools.drawAnnotations(plt.imread(image_files[image_no]), easy_results, ax=ax)\n",
    "\n",
    "    ax.set_title('Easy OCR Result Example')\n",
    "\n",
    "    # Save the annotated image with improved quality\n",
    "    output_file = 'C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output_easy_ocr/annotated_'+img_name_temp+'.jpg'\n",
    "    plt.savefig(output_file, dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "    print(filtered_df.head(20))\n",
    "    \n",
    "    final_df = final_df.append(filtered_df, ignore_index=True)\n",
    "\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a906a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e22d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['text'] = final_df['text'].str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a05af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd5e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace_mapping = {\n",
    "# 'COUPON VARIES COUPOM VARIES': 'DIGITAL COUPON',\n",
    "# 'COUPONAA': 'DIGITAL COUPON'\n",
    "# }\n",
    "\n",
    "# final_df['text'] = final_df['text'].replace(replace_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d851743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc1a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_counts_per_page = final_df.groupby(['page_number', 'text'])['text'].count().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3406e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_counts_per_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07403637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coupon_counts_per_page.to_excel('output_result.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3438df55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
