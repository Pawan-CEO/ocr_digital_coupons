{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# import mpldatacursor\n",
    "\n",
    "from PIL import Image\n",
    "from PyPDF2 import PdfReader\n",
    "from matplotlib.widgets import Cursor, SpanSelector\n",
    "\n",
    "# import pytesseract\n",
    "import easyocr\n",
    "import keras_ocr\n",
    "from keras_ocr.tools import drawAnnotations\n",
    "import re\n",
    "import os\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Images from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_from_pdf(pdf_path, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load the PDF file\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "\n",
    "    # Loop through each page of the PDF\n",
    "    for page_number, page in enumerate(pdf_reader.pages):\n",
    "        # Extract images from the page\n",
    "        xObject = page['/Resources']['/XObject'].get_object()\n",
    "        image_counter = 0\n",
    "\n",
    "        for obj in xObject:\n",
    "            if xObject[obj]['/Subtype'] == '/Image':\n",
    "                size = (xObject[obj]['/Width'], xObject[obj]['/Height'])\n",
    "                data = xObject[obj].get_object()\n",
    "\n",
    "                if '/Filter' in data:\n",
    "                    if data['/Filter'] == '/FlateDecode':\n",
    "                        img = Image.frombytes('RGB', size, data.get_data())\n",
    "                        img.save(os.path.join(output_folder, f\"page_{page_number + 1}_image_{image_counter}.png\"))\n",
    "                        image_counter += 1\n",
    "                    elif data['/Filter'] == '/DCTDecode':\n",
    "                        img = open(os.path.join(output_folder, f\"page_{page_number + 1}_image_{image_counter}.jpg\"), \"wb\")\n",
    "                        img.write(data.get_data())\n",
    "                        img.close()\n",
    "                        image_counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path = \"C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/data/Jewelosco.pdf\"\n",
    "output_image_folder_path = \"C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/data/image\"\n",
    "\n",
    "extract_images_from_pdf(pdf_file_path, output_image_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For all images using Easy OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "reader = easyocr.Reader(['en'], gpu = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob('C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/data/image/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the functions\n",
    "\n",
    "# Function to check if the second word is not 'coupon' or 'rebate'\n",
    "def check_second_word(text):\n",
    "    words = text.lower().split()\n",
    "    if len(words)==2:\n",
    "        return words[1] in ['coupon', 'rebate','only','offers', 'offer']\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def check_length(text):\n",
    "    w_text = text.lower().split()\n",
    "    words = max(len('coupon'), len('rebate'), len('digital'),len('offers'), len('only'))\n",
    "    # print('Threshold length:',words)\n",
    "    if len(w_text) == 1:\n",
    "        # print('Actual Word Length:', len(w_text[0]))\n",
    "        return len(w_text[0])<=words\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# Your original code\n",
    "dfs = []\n",
    "for img in image_files:\n",
    "    result = reader.readtext(img)\n",
    "    img_df = pd.DataFrame(result, columns=['bbox','text','conf'])\n",
    "\n",
    "    # Convert the 'text' column to lowercase and filter rows where the lowercase text starts with the strings\n",
    "    filtered_df = img_df[img_df['text'].str.lower().str.startswith(('digh', 'reb', 'digital', 'coup', 'dig','offe','only',), na=False)]\n",
    "    strings_list = ['digital rebate', 'digital coupon','digital only offers','digital-only offers']\n",
    "    # Find the maximum length among the given strings\n",
    "    max_length = max(len(s) for s in strings_list)\n",
    "    # Filter the DataFrame based on the maximum length\n",
    "    filtered_df = filtered_df[filtered_df['text'].str.len() <= max_length]\n",
    "\n",
    "    ##Getting the page number\n",
    "    img_id = img.split('\\\\')[1]\n",
    "    page_number = re.search(r'page_(\\d+)', img_id).group(1)\n",
    "    print(page_number)\n",
    "    filtered_df['page_number'] = page_number\n",
    "\n",
    "#     # Check if each string in the 'text' column has exactly two words\n",
    "    word_count = filtered_df['text'].str.split().apply(len)\n",
    "    has_second_string = word_count == 3\n",
    "    \n",
    "#     # Drop the rows where the 'text' column has more than three words\n",
    "    filtered_df = filtered_df[~(word_count > 3)]\n",
    "\n",
    "#     if not filtered_df.empty:\n",
    "        # Filtering out records with \"coupon\" or \"rebate\" in the second string\n",
    "#         filtered_df = filtered_df[filtered_df['text'].apply(check_second_word)]\n",
    "        # Apply the function on 'text_column' and create a boolean mask\n",
    "#         filtered_df = filtered_df[filtered_df['text'].apply(check_length)]\n",
    "\n",
    "    dfs.append(filtered_df)\n",
    "#     dfs.append(img_df)\n",
    "\n",
    "easyocr_df = pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123 = dfs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox</th>\n",
       "      <th>text</th>\n",
       "      <th>conf</th>\n",
       "      <th>page_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>[[23, 1363], [77, 1363], [77, 1377], [23, 1377]]</td>\n",
       "      <td>DIGitAL</td>\n",
       "      <td>0.357780</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>[[137, 1363], [191, 1363], [191, 1377], [137, ...</td>\n",
       "      <td>DIGitaL</td>\n",
       "      <td>0.386418</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>[[25, 1375], [87, 1375], [87, 1391], [25, 1391]]</td>\n",
       "      <td>COUPON</td>\n",
       "      <td>0.978685</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>[[137, 1377], [199, 1377], [199, 1391], [137, ...</td>\n",
       "      <td>CouPOn</td>\n",
       "      <td>0.142411</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>[[559, 1591], [643, 1591], [643, 1607], [559, ...</td>\n",
       "      <td>DIgITAL COUPON</td>\n",
       "      <td>0.369390</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[599, 263], [669, 263], [669, 275], [599, 275]]</td>\n",
       "      <td>COUPom S1.29e0,</td>\n",
       "      <td>0.146069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[[603, 437], [671, 437], [671, 449], [603, 449]]</td>\n",
       "      <td>coupon VaRies</td>\n",
       "      <td>0.308107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>[[601, 793], [673, 793], [673, 805], [601, 805]]</td>\n",
       "      <td>Coupom VARIES</td>\n",
       "      <td>0.306010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>[[31, 1441], [69, 1441], [69, 1453], [31, 1453]]</td>\n",
       "      <td>REBATE</td>\n",
       "      <td>0.940066</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[[359, 935], [485, 935], [485, 955], [359, 955]]</td>\n",
       "      <td>DIGITAL COUPON</td>\n",
       "      <td>0.818094</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>[[298, 512], [340, 512], [340, 520], [298, 520]]</td>\n",
       "      <td>couponaa</td>\n",
       "      <td>0.078452</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>[[357, 1255], [401, 1255], [401, 1267], [357, ...</td>\n",
       "      <td>COUPON</td>\n",
       "      <td>0.987229</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>[[463, 1253], [507, 1253], [507, 1267], [463, ...</td>\n",
       "      <td>REBATE</td>\n",
       "      <td>0.838415</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>[[569, 1253], [613, 1253], [613, 1267], [569, ...</td>\n",
       "      <td>REBATE</td>\n",
       "      <td>0.532097</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>[[25, 1445], [71, 1445], [71, 1457], [25, 1457]]</td>\n",
       "      <td>DIghAl</td>\n",
       "      <td>0.155563</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>[[155, 1445], [203, 1445], [203, 1457], [155, ...</td>\n",
       "      <td>DIGgal</td>\n",
       "      <td>0.328108</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>[[25, 1455], [77, 1455], [77, 1469], [25, 1469]]</td>\n",
       "      <td>COUPON</td>\n",
       "      <td>0.612128</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>[[157, 1455], [209, 1455], [209, 1469], [157, ...</td>\n",
       "      <td>COUPON</td>\n",
       "      <td>0.974782</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>[[195, 1343], [245, 1343], [245, 1357], [195, ...</td>\n",
       "      <td>DIGgial</td>\n",
       "      <td>0.160176</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>[[195, 1353], [251, 1353], [251, 1369], [195, ...</td>\n",
       "      <td>COUpOn</td>\n",
       "      <td>0.300632</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>[[361, 1545], [411, 1545], [411, 1559], [361, ...</td>\n",
       "      <td>digital</td>\n",
       "      <td>0.682560</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>[[361, 1557], [409, 1557], [409, 1571], [361, ...</td>\n",
       "      <td>REBATE</td>\n",
       "      <td>0.992958</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[[359, 391], [475, 391], [475, 405], [359, 405]]</td>\n",
       "      <td>DIGital-ONLY OFFER</td>\n",
       "      <td>0.506015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>[[359, 915], [475, 915], [475, 929], [359, 929]]</td>\n",
       "      <td>DIGITAL-ONLY OFFER</td>\n",
       "      <td>0.407449</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>[[357, 1401], [457, 1401], [457, 1415], [357, ...</td>\n",
       "      <td>digmalfonly Orfer</td>\n",
       "      <td>0.252941</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[528, 111], [665, 111], [665, 127], [528, 127]]</td>\n",
       "      <td>DIGItAL-ONLY OFFER</td>\n",
       "      <td>0.417903</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>[[529, 1113], [665, 1113], [665, 1129], [529, ...</td>\n",
       "      <td>DIGItAL-ONLY OFFER</td>\n",
       "      <td>0.400391</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>[[47, 1143], [165, 1143], [165, 1157], [47, 11...</td>\n",
       "      <td>digital-OnLY OFFer</td>\n",
       "      <td>0.140486</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>[[203, 1143], [321, 1143], [321, 1157], [203, ...</td>\n",
       "      <td>DIGITAL-ONLY OFFeR</td>\n",
       "      <td>0.453315</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>[[529, 1369], [665, 1369], [665, 1385], [529, ...</td>\n",
       "      <td>DIGItALONLY OFFER</td>\n",
       "      <td>0.689497</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>[[47, 1389], [165, 1389], [165, 1403], [47, 14...</td>\n",
       "      <td>DIGItal-ONLY OFFER</td>\n",
       "      <td>0.356279</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>[[203, 1389], [321, 1389], [321, 1403], [203, ...</td>\n",
       "      <td>DIGITAL ONLY OFFER</td>\n",
       "      <td>0.594689</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>[[359, 1389], [475, 1389], [475, 1403], [359, ...</td>\n",
       "      <td>Digital-ONLY OFFER</td>\n",
       "      <td>0.623137</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  bbox                text  \\\n",
       "302   [[23, 1363], [77, 1363], [77, 1377], [23, 1377]]             DIGitAL   \n",
       "303  [[137, 1363], [191, 1363], [191, 1377], [137, ...             DIGitaL   \n",
       "305   [[25, 1375], [87, 1375], [87, 1391], [25, 1391]]              COUPON   \n",
       "306  [[137, 1377], [199, 1377], [199, 1391], [137, ...              CouPOn   \n",
       "342  [[559, 1591], [643, 1591], [643, 1607], [559, ...      DIgITAL COUPON   \n",
       "13    [[599, 263], [669, 263], [669, 275], [599, 275]]     COUPom S1.29e0,   \n",
       "30    [[603, 437], [671, 437], [671, 449], [603, 449]]       coupon VaRies   \n",
       "63    [[601, 793], [673, 793], [673, 805], [601, 805]]       Coupom VARIES   \n",
       "242   [[31, 1441], [69, 1441], [69, 1453], [31, 1453]]              REBATE   \n",
       "96    [[359, 935], [485, 935], [485, 955], [359, 955]]      DIGITAL COUPON   \n",
       "89    [[298, 512], [340, 512], [340, 520], [298, 520]]            couponaa   \n",
       "253  [[357, 1255], [401, 1255], [401, 1267], [357, ...              COUPON   \n",
       "254  [[463, 1253], [507, 1253], [507, 1267], [463, ...              REBATE   \n",
       "255  [[569, 1253], [613, 1253], [613, 1267], [569, ...              REBATE   \n",
       "277   [[25, 1445], [71, 1445], [71, 1457], [25, 1457]]              DIghAl   \n",
       "278  [[155, 1445], [203, 1445], [203, 1457], [155, ...              DIGgal   \n",
       "279   [[25, 1455], [77, 1455], [77, 1469], [25, 1469]]              COUPON   \n",
       "280  [[157, 1455], [209, 1455], [209, 1469], [157, ...              COUPON   \n",
       "242  [[195, 1343], [245, 1343], [245, 1357], [195, ...             DIGgial   \n",
       "246  [[195, 1353], [251, 1353], [251, 1369], [195, ...              COUpOn   \n",
       "291  [[361, 1545], [411, 1545], [411, 1559], [361, ...             digital   \n",
       "293  [[361, 1557], [409, 1557], [409, 1571], [361, ...              REBATE   \n",
       "56    [[359, 391], [475, 391], [475, 405], [359, 405]]  DIGital-ONLY OFFER   \n",
       "136   [[359, 915], [475, 915], [475, 929], [359, 929]]  DIGITAL-ONLY OFFER   \n",
       "190  [[357, 1401], [457, 1401], [457, 1415], [357, ...   digmalfonly Orfer   \n",
       "2     [[528, 111], [665, 111], [665, 127], [528, 127]]  DIGItAL-ONLY OFFER   \n",
       "122  [[529, 1113], [665, 1113], [665, 1129], [529, ...  DIGItAL-ONLY OFFER   \n",
       "123  [[47, 1143], [165, 1143], [165, 1157], [47, 11...  digital-OnLY OFFer   \n",
       "124  [[203, 1143], [321, 1143], [321, 1157], [203, ...  DIGITAL-ONLY OFFeR   \n",
       "164  [[529, 1369], [665, 1369], [665, 1385], [529, ...   DIGItALONLY OFFER   \n",
       "165  [[47, 1389], [165, 1389], [165, 1403], [47, 14...  DIGItal-ONLY OFFER   \n",
       "166  [[203, 1389], [321, 1389], [321, 1403], [203, ...  DIGITAL ONLY OFFER   \n",
       "167  [[359, 1389], [475, 1389], [475, 1403], [359, ...  Digital-ONLY OFFER   \n",
       "\n",
       "         conf page_number  \n",
       "302  0.357780          11  \n",
       "303  0.386418          11  \n",
       "305  0.978685          11  \n",
       "306  0.142411          11  \n",
       "342  0.369390          11  \n",
       "13   0.146069           1  \n",
       "30   0.308107           1  \n",
       "63   0.306010           1  \n",
       "242  0.940066           2  \n",
       "96   0.818094           3  \n",
       "89   0.078452           4  \n",
       "253  0.987229           5  \n",
       "254  0.838415           5  \n",
       "255  0.532097           5  \n",
       "277  0.155563           5  \n",
       "278  0.328108           5  \n",
       "279  0.612128           5  \n",
       "280  0.974782           5  \n",
       "242  0.160176           7  \n",
       "246  0.300632           7  \n",
       "291  0.682560           7  \n",
       "293  0.992958           7  \n",
       "56   0.506015           8  \n",
       "136  0.407449           8  \n",
       "190  0.252941           8  \n",
       "2    0.417903           9  \n",
       "122  0.400391           9  \n",
       "123  0.140486           9  \n",
       "124  0.453315           9  \n",
       "164  0.689497           9  \n",
       "165  0.356279           9  \n",
       "166  0.594689           9  \n",
       "167  0.623137           9  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easyocr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First goal is to get all the annotated images and save it to a folder by enhancing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare(img_fn, easyocr_df, page):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    easy_results = easyocr_df[['text','bbox']].values.tolist()\n",
    "    # print(easy_results)\n",
    "\n",
    "    easy_results = [(x[0], np.array(x[1])) for x in easy_results]\n",
    "    keras_ocr.tools.drawAnnotations(plt.imread(img_fn), easy_results, ax=ax)\n",
    "    ax.set_title('Easy OCR Result Example')\n",
    "\n",
    "    # Save the annotated image with improved quality\n",
    "    output_file = f'C:/Users/pmehra/Desktop/ocr/Adhoc-image-project/output_easy_ocr/annotated_image_{page}.jpg'\n",
    "    plt.savefig(output_file, dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_repor = []\n",
    "for index, img_path in enumerate(image_files):\n",
    "    if not df123[index].empty:  # Check if the DataFrame is not empty\n",
    "        print('Algo has captured the target...')\n",
    "        print(index)\n",
    "\n",
    "        ##Getting the page number\n",
    "        img_id = img_path.split('\\\\')[1]\n",
    "        page_number = re.search(r'page_(\\d+)', img_id).group(1)\n",
    "        print(page_number)\n",
    "        plot_compare(img_path, df123[index], page_number)\n",
    "\n",
    "        # filtered_df, grouped_df = merge_logic(dfs[index])\n",
    "        # print(filtered_df)\n",
    "        # df_report.append(filtered_df)\n",
    "    else:\n",
    "        print(f\"Skipping index {index} as the DataFrame is empty.\")\n",
    "    # print(index, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merger close proximity strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_distance(bbox1, bbox2):\n",
    "    x1, y1 = bbox1[0]\n",
    "    x2, y2 = bbox1[1]\n",
    "    x3, y3 = bbox2[0]\n",
    "    x4, y4 = bbox2[1]\n",
    "\n",
    "    center1_x = (x1 + x2) / 2\n",
    "    center1_y = (y1 + y2) / 2\n",
    "    center2_x = (x3 + x4) / 2\n",
    "    center2_y = (y3 + y4) / 2\n",
    "\n",
    "    dist1 = abs(center1_x - center2_x)\n",
    "    dist2 = abs(center1_y - center2_y) \n",
    "\n",
    "    return dist1,dist2\n",
    "\n",
    "def merge_logic(df):\n",
    "\n",
    "    grouped_text = []\n",
    "    grouped_indices = []\n",
    "    grouped_conf = []\n",
    "    group_threshold =20\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        index_track = []\n",
    "\n",
    "        if idx in [item for sublist in grouped_indices for item in sublist]:\n",
    "            continue\n",
    "\n",
    "        text = row['text']\n",
    "        conf = row['conf']\n",
    "        grouped = False\n",
    "\n",
    "        if idx == (df.shape[0]-1):\n",
    "            break\n",
    "\n",
    "        for idx2, row2 in df.iterrows():\n",
    "            \n",
    "            if idx2 == idx or idx2 in [item for sublist in grouped_indices for item in sublist]:\n",
    "                continue\n",
    "\n",
    "            bbox1 = eval(row['bbox']) if isinstance(row['bbox'], str) else row['bbox']\n",
    "            bbox2 = eval(row2['bbox']) if isinstance(row2['bbox'], str) else row2['bbox']\n",
    "            \n",
    "            if horizontal_distance(bbox1, bbox2) <= group_threshold:\n",
    "\n",
    "                text += ' ' + row2['text']\n",
    "                conf = max(conf, row2['conf'])\n",
    "\n",
    "                index_track.append(idx2)\n",
    "                # conf_track.append(conf)\n",
    "                grouped = True\n",
    "\n",
    "        if grouped:\n",
    "\n",
    "            grouped_text.append(text)\n",
    "            grouped_conf.append(conf)\n",
    "            index_track = [idx] + index_track\n",
    "            grouped_indices.append(index_track)\n",
    "\n",
    "    grouped_data = {'text': grouped_text, 'merged_indices': grouped_indices, 'conf': grouped_conf}\n",
    "    grouped_df = pd.DataFrame(grouped_data)\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "def merge_original_df(grouped_df, df):\n",
    "\n",
    "    # Iterate through rows of merge_df\n",
    "    for _, row in grouped_df.iterrows():\n",
    "        merged_indices = row['merged_indices']\n",
    "        merged_text = row['text']\n",
    "        max_conf = row['conf']\n",
    "        \n",
    "        # Update the original DataFrame with merged data\n",
    "        df.loc[merged_indices[0], 'text'] = merged_text\n",
    "        df.loc[merged_indices[0], 'conf'] = max_conf\n",
    "        \n",
    "        # Drop the rows at merged indices\n",
    "        df.drop(index=merged_indices[1:], inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123 = dfs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = []\n",
    "for df in df123:\n",
    "    if not df.empty:  # Check if the DataFrame is not empty\n",
    "        print('Algo has captured the target...')\n",
    "        print(df)\n",
    "        print('Grouped......................')\n",
    "        grouped_df = merge_logic(df)\n",
    "        print(grouped_df)\n",
    "\n",
    "        \n",
    "        output = merge_original_df(grouped_df, df)\n",
    "        print(output)\n",
    "        df_report.append(output)\n",
    "        \n",
    "        # print(filtered_df)\n",
    "        # df_report.append(filtered_df)\n",
    "    else:\n",
    "        print(f\"Skipping index as the DataFrame is empty.\")\n",
    "        df_report.append(pd.DataFrame())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing enrichment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate DataFrames\n",
    "df_report = pd.concat(df_report)\n",
    "\n",
    "# Reset index\n",
    "df_report.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping to the desired string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_text(text):\n",
    "    words = text.lower().split()\n",
    "\n",
    "    if len(words) == 2:\n",
    "        if words[0].startswith('dig') and words[1].startswith('coup'):\n",
    "            return 'DIGITAL COUPON'\n",
    "        elif words[0].startswith('dig') and words[1].startswith('reb'):\n",
    "            return 'DIGITAL REBATE'\n",
    "    elif len(words) == 1:\n",
    "        if words[0].startswith('coup'):\n",
    "            return 'DIGITAL COUPON'\n",
    "        elif words[0].startswith('reb'):\n",
    "            return 'DIGITAL REBATE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_cpy = df_report.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mapping function to 'text' column\n",
    "df_report_cpy['text'] = df_report_cpy['text'].apply(map_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with page_number and text columns\n",
    "page_counts = df_report_cpy.groupby(['page_number', 'text']).size().reset_index(name='count')\n",
    "# page_counts.drop(columns = ['text'], inplace=True)\n",
    "page_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = page_counts.pivot(index='page_number', columns='text', values='count').fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.reset_index(level=0, inplace=True)\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = list(pivot_df['page_number'].values)\n",
    "\n",
    "DIGITAL_COUPON = list(pivot_df['DIGITAL COUPON'].values)\n",
    "\n",
    "DIGITAL_REBATE = list(pivot_df['DIGITAL REBATE'].values)\n",
    "\n",
    "# Create a DataFrame from the arrays\n",
    "data = {'page': page, 'DIGITAL COUPON': DIGITAL_COUPON, 'DIGITAL REBATE': DIGITAL_REBATE}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing numbers to columns and fill other columns with 0\n",
    "numbers  = list(range(1,14))\n",
    "for number in numbers:\n",
    "    if number not in df['page']:\n",
    "        new_row = [number] + [0] * (df.shape[1] - 1)\n",
    "        df.loc[len(df)] = new_row\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
